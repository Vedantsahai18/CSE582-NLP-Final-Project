{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0ZhUm14DVMU",
        "outputId": "cd41967a-0a67-40b2-c2ec-690df177c49d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MemSum'...\n",
            "remote: Enumerating objects: 275, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 275 (delta 7), reused 2 (delta 2), pack-reused 266\u001b[K\n",
            "Receiving objects: 100% (275/275), 82.32 MiB | 22.01 MiB/s, done.\n",
            "Resolving deltas: 100% (104/104), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nianlonggu/MemSum.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3g3D88DEFI3",
        "outputId": "ed68f5df-5638-437b-9ab8-1fdc56ce8a3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config\n",
            "data\n",
            "Data_processing_training_and_testing_for_MemSum.ipynb\n",
            "human_eval_results\n",
            "images\n",
            "MemSum_Human_Evaluation.ipynb\n",
            "oracle_score_compute.ipynb\n",
            "README.md\n",
            "requirements.txt\n",
            "slides_for_paper.pdf\n",
            "src\n",
            "summarizers.py\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"MemSum\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Fw1sOX0AEUzV"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ky4m3pQNSAVB",
        "outputId": "fcf5ca82-bd97-4a49-bd45-6cbe5058ff7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q0tTRp8Golc",
        "outputId": "7df41edd-e3e8-49dd-a1ca-6987a05f755f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1977\n",
            "dict_keys(['text', 'summary'])\n",
            "The\n",
            "The\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "# train_corpus = [ json.loads(line) for line in open(\"data/custom_data/train_CUSTOM_raw.jsonl\") ]\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/dataset/corpusfinal.csv')\n",
        "train_corpus = []\n",
        "for i in range(len(df)):\n",
        "  dick = {}\n",
        "  dick['text'] = df['document'][i]\n",
        "  dick['summary'] = df['ext_summary'][i]\n",
        "  train_corpus.append(dick)\n",
        "\n",
        "## as an example, we have 100 instances for training\n",
        "print(len(train_corpus))\n",
        "print(train_corpus[0].keys())\n",
        "print(train_corpus[0][\"text\"][:3])\n",
        "print(train_corpus[0][\"summary\"][:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ThmF2tO8EWcQ"
      },
      "outputs": [],
      "source": [
        "from src.data_preprocessing.MemSum.utils import greedy_extract\n",
        "import json\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8lqASfWFTWj",
        "outputId": "9c7a2f7a-2c5d-468d-b533-a1b6ed688c84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1383/1383 [02:53<00:00,  7.97it/s]\n"
          ]
        }
      ],
      "source": [
        "# train_corpus = [ json.loads(line) for line in open(\"data/custom_data/train_CUSTOM_raw.jsonl\") ]\n",
        "df = pd.read_csv('/content/drive/MyDrive/dataset/corpusfinal.csv')\n",
        "df_train = df.iloc[:int(len(df)*0.7)]\n",
        "train_corpus = []\n",
        "for i in range(len(df_train)):\n",
        "  dick = {}\n",
        "  dick['text'] = df_train['document'][i].split(\".\")\n",
        "  dick['summary'] = df_train['ext_summary'][i].split(\".\")\n",
        "  train_corpus.append(dick)\n",
        "\n",
        "# train_corpus[0]\n",
        "for data in tqdm(train_corpus):\n",
        "    high_rouge_episodes = greedy_extract( data[\"text\"], data[\"summary\"], beamsearch_size = 3 )\n",
        "    indices_list = []\n",
        "    score_list  = []\n",
        "\n",
        "    for indices, score in high_rouge_episodes:\n",
        "        indices_list.append( indices )\n",
        "        score_list.append(score)\n",
        "\n",
        "    data[\"indices\"] = indices_list\n",
        "    data[\"score\"] = score_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Q4Ow4PMDJIAO"
      },
      "outputs": [],
      "source": [
        "with open(\"data/train_CUSTOM_labelled.jsonl\",\"w\") as f:\n",
        "    for data in train_corpus:\n",
        "        f.write(json.dumps(data) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "InGexStDK6v4"
      },
      "outputs": [],
      "source": [
        "df_test = df.iloc[int(len(df)*0.7):]\n",
        "test_corpus = []\n",
        "df_test\n",
        "for i,row in df_test.iterrows():\n",
        "  dick1 = {}\n",
        "  dick1['text'] = row['document'].split(\".\")\n",
        "  dick1['summary'] = str(row ['ext_summary']).split(\".\")\n",
        "  test_corpus.append(dick)\n",
        "with open(\"data/val_CUSTOM_raw.jsonl\",\"w\") as f:\n",
        "    for data in test_corpus:\n",
        "        f.write(json.dumps(data) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJuK4zGCK8sC",
        "outputId": "28bcbd49-0e8d-4d05-ea9b-34bd19eb3f34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder list\n",
            "Processing file 1SVTHcgWJDvoVCsLfdvkaw5ICkihjUoaH unigram_embeddings_200dim.pkl\n",
            "Processing file 1SuF4HSe0-IBKWGtc1xqlzMHNDneiLi4- vocabulary_200dim.pkl\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SVTHcgWJDvoVCsLfdvkaw5ICkihjUoaH\n",
            "To: /content/MemSum/MemSum/MemSum/model/glove/unigram_embeddings_200dim.pkl\n",
            "100% 320M/320M [00:01<00:00, 163MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SuF4HSe0-IBKWGtc1xqlzMHNDneiLi4-\n",
            "To: /content/MemSum/MemSum/MemSum/model/glove/vocabulary_200dim.pkl\n",
            "100% 4.16M/4.16M [00:00<00:00, 237MB/s]\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown -q\n",
        "try:\n",
        "    os.system(\"rm -r model\")\n",
        "    os.makedirs(\"model/\")\n",
        "except:\n",
        "    pass\n",
        "!cd model/; gdown --folder https://drive.google.com/drive/folders/1lrwYrrM3h0-9fwWCOmpRkydvmF6hmvmW\n",
        "\n",
        "\n",
        "if not os.path.exists(\"model/glove\"):\n",
        "    try:\n",
        "        os.makedirs(\"model/glove\")\n",
        "        os.system(\"mv model/*.pkl model/glove/\")\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPnWLxpkMYLy",
        "outputId": "d2ec53d3-d4b2-43bd-b1db-fc8e16916321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0it [00:00, ?it/s]\r1383it [00:00, 67361.75it/s]\n",
            "\r0it [00:00, ?it/s]\r594it [00:00, 52776.42it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "0it [00:00, ?it/s]/content/MemSum/MemSum/MemSum/src/MemSum_Full/train.py:227: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  remaining_mask_np = np.ones_like( doc_mask_np ).astype( np.bool ) | doc_mask_np\n",
            "/content/MemSum/MemSum/MemSum/src/MemSum_Full/train.py:228: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  extraction_mask_np = np.zeros_like( doc_mask_np ).astype( np.bool ) | doc_mask_np\n",
            "99it [00:58,  1.54it/s][current_batch: 00100] loss: 1.905, learning rate: 0.000100\n",
            "199it [01:58,  1.68it/s][current_batch: 00200] loss: 1.835, learning rate: 0.000100\n",
            "299it [02:56,  1.72it/s][current_batch: 00300] loss: 1.770, learning rate: 0.000100\n",
            "399it [03:56,  1.74it/s][current_batch: 00400] loss: 1.767, learning rate: 0.000100\n",
            "499it [04:55,  1.65it/s][current_batch: 00500] loss: 1.731, learning rate: 0.000100\n",
            "599it [05:55,  1.66it/s][current_batch: 00600] loss: 1.769, learning rate: 0.000100\n",
            "690it [06:48,  1.71it/s]Starting validation ...\n",
            "/content/MemSum/MemSum/MemSum/src/MemSum_Full/train.py:308: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  remaining_mask_np = np.ones_like( doc_mask ).astype( np.bool ) | doc_mask\n",
            "/content/MemSum/MemSum/MemSum/src/MemSum_Full/train.py:309: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  extraction_mask_np = np.zeros_like( doc_mask ).astype( np.bool ) | doc_mask\n",
            "val: 0.7341, 0.6221, 0.7225\n",
            "691it [08:00,  1.44it/s]\n",
            "8it [00:05,  1.65it/s][current_batch: 00700] loss: 0.160, learning rate: 0.000100\n",
            "108it [01:04,  1.71it/s][current_batch: 00800] loss: 1.746, learning rate: 0.000100\n",
            "208it [02:04,  1.74it/s][current_batch: 00900] loss: 1.752, learning rate: 0.000100\n",
            "308it [03:03,  1.76it/s][current_batch: 01000] loss: 1.762, learning rate: 0.000100\n",
            "Starting validation ...\n",
            "val: 0.6239, 0.4282, 0.6006\n",
            "408it [05:14,  1.67it/s][current_batch: 01100] loss: 1.744, learning rate: 0.000100\n",
            "508it [06:14,  1.62it/s][current_batch: 01200] loss: 1.732, learning rate: 0.000100\n",
            "608it [07:14,  1.65it/s][current_batch: 01300] loss: 1.730, learning rate: 0.000100\n",
            "690it [08:03,  1.69it/s]Starting validation ...\n",
            "val: 0.7341, 0.6221, 0.7225\n",
            "691it [09:16,  1.24it/s]\n",
            "17it [00:09,  1.68it/s][current_batch: 01400] loss: 0.312, learning rate: 0.000100\n",
            "117it [01:10,  1.64it/s][current_batch: 01500] loss: 1.784, learning rate: 0.000100\n",
            "217it [02:09,  1.66it/s][current_batch: 01600] loss: 1.724, learning rate: 0.000100\n",
            "317it [03:08,  1.79it/s][current_batch: 01700] loss: 1.726, learning rate: 0.000100\n",
            "417it [04:07,  1.61it/s][current_batch: 01800] loss: 1.749, learning rate: 0.000100\n",
            "517it [05:06,  1.60it/s][current_batch: 01900] loss: 1.732, learning rate: 0.000100\n",
            "617it [06:05,  1.73it/s][current_batch: 02000] loss: 1.718, learning rate: 0.000100\n",
            "Starting validation ...\n",
            "val: 0.7341, 0.6221, 0.7225\n",
            "690it [08:00,  1.65it/s]Starting validation ...\n",
            "val: 0.7341, 0.6221, 0.7225\n",
            "691it [09:13,  1.25it/s]\n",
            "26it [00:15,  1.71it/s][current_batch: 02100] loss: 0.475, learning rate: 0.000100\n",
            "126it [01:15,  1.73it/s][current_batch: 02200] loss: 1.745, learning rate: 0.000100\n",
            "226it [02:15,  1.66it/s][current_batch: 02300] loss: 1.732, learning rate: 0.000100\n",
            "326it [03:14,  1.56it/s][current_batch: 02400] loss: 1.697, learning rate: 0.000100\n",
            "426it [04:14,  1.56it/s][current_batch: 02500] loss: 1.767, learning rate: 0.000100\n",
            "526it [05:13,  1.68it/s][current_batch: 02600] loss: 1.763, learning rate: 0.000100\n",
            "626it [06:13,  1.66it/s][current_batch: 02700] loss: 1.762, learning rate: 0.000100\n",
            "690it [06:51,  1.71it/s]Starting validation ...\n",
            "val: 0.7341, 0.6221, 0.7225\n",
            "691it [08:04,  1.43it/s]\n",
            "35it [00:21,  1.73it/s][current_batch: 02800] loss: 0.635, learning rate: 0.000100\n",
            "135it [01:21,  1.64it/s][current_batch: 02900] loss: 1.744, learning rate: 0.000100\n",
            "235it [02:22,  1.70it/s][current_batch: 03000] loss: 1.707, learning rate: 0.000100\n",
            "Starting validation ...\n",
            "val: 0.7341, 0.6221, 0.7225\n",
            "335it [04:34,  1.70it/s][current_batch: 03100] loss: 1.770, learning rate: 0.000100\n",
            "435it [05:35,  1.75it/s][current_batch: 03200] loss: 1.709, learning rate: 0.000100\n",
            "535it [06:35,  1.62it/s][current_batch: 03300] loss: 1.732, learning rate: 0.000100\n",
            "635it [07:36,  1.55it/s][current_batch: 03400] loss: 1.745, learning rate: 0.000100\n",
            "690it [08:09,  1.71it/s]Starting validation ...\n",
            "val: 0.7341, 0.6221, 0.7225\n",
            "691it [09:21,  1.23it/s]\n"
          ]
        }
      ],
      "source": [
        "!cd src/MemSum_Full; python train.py -training_corpus_file_name ../../data/train_CUSTOM_labelled.jsonl -validation_corpus_file_name ../../data/val_CUSTOM_raw.jsonl -model_folder ../../model/MemSum_Full/custom_data/200dim/run1/ -log_folder ../../log/MemSum_Full/custom_data/200dim/run1/ -vocabulary_file_name ../../model/glove/vocabulary_200dim.pkl -pretrained_unigram_embeddings_file_name ../../model/glove/unigram_embeddings_200dim.pkl -max_seq_len 100 -max_doc_len 500 -num_of_epochs 5 -save_every 1000 -n_device 1 -batch_size_per_device 2 -max_extracted_sentences_per_document 7 -moving_average_decay 0.999 -p_stop_thres 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5ziC45_cSfu9"
      },
      "outputs": [],
      "source": [
        "from summarizers import MemSum\n",
        "from tqdm import tqdm\n",
        "from rouge_score import rouge_scorer\n",
        "import json\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bcAh047kSjLj"
      },
      "outputs": [],
      "source": [
        "rouge_cal = rouge_scorer.RougeScorer(['rouge1','rouge2', 'rougeLsum'], use_stemmer=True)\n",
        "\n",
        "memsum_custom_data = MemSum( \"model/MemSum_Full/custom_data/200dim/run1/model_batch_3455.pt\", \n",
        "                  \"model/glove/vocabulary_200dim.pkl\", \n",
        "                  gpu = 0 ,  max_doc_len = 500  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "FJODv4CcUVwb"
      },
      "outputs": [],
      "source": [
        "# test_corpus_custom_data = [ json.loads(line) for line in open(\"data/custom_data/test_CUSTOM_raw.jsonl\")]\n",
        "df_val = pd.read_csv('/content/drive/MyDrive/dataset/corpusfinal.csv')\n",
        "df_test = df.iloc[:int(len(df)*0.3)]\n",
        "test_corpus_custom_data = []\n",
        "df_test\n",
        "for i,row in df_test.iterrows():\n",
        "  dick1 = {}\n",
        "  dick1['text'] = row['document'].split(\".\")\n",
        "  dick1['summary'] = str(row['ext_summary']).split(\".\")\n",
        "  test_corpus_custom_data.append(dick)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "c6f3Up_1UiWz"
      },
      "outputs": [],
      "source": [
        "def evaluate( model, corpus, p_stop, max_extracted_sentences, rouge_cal ):\n",
        "    scores = []\n",
        "    for data in tqdm(corpus):\n",
        "        gold_summary = data[\"summary\"]\n",
        "        extracted_summary = model.extract( [data[\"text\"]], p_stop_thres = p_stop, max_extracted_sentences_per_document = max_extracted_sentences )[0]\n",
        "        \n",
        "        score = rouge_cal.score( \"\\n\".join( gold_summary ), \"\\n\".join(extracted_summary)  )\n",
        "        scores.append( [score[\"rouge1\"].fmeasure, score[\"rouge2\"].fmeasure, score[\"rougeLsum\"].fmeasure ] )\n",
        "    \n",
        "    return np.asarray(scores).mean(axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaUWUcW0Ul9t",
        "outputId": "d9642f83-7558-488f-d71b-d2798df17251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 593/593 [01:34<00:00,  6.26it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.73410405, 0.62209302, 0.71676301])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "evaluate( memsum_custom_data, test_corpus_custom_data, 0.6, 7, rouge_cal )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Gy1mg1Z5VU-",
        "outputId": "ab550aec-deb5-4550-ec02-169a5de06f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/MemSum/ (stored 0%)\n",
            "  adding: content/MemSum/human_eval_results/ (stored 0%)\n",
            "  adding: content/MemSum/human_eval_results/records_memsum_wo_autostop_neusum.jsonl (deflated 76%)\n",
            "  adding: content/MemSum/human_eval_results/records_memsum_neusum.jsonl (deflated 76%)\n",
            "  adding: content/MemSum/.git/ (stored 0%)\n",
            "  adding: content/MemSum/.git/branches/ (stored 0%)\n",
            "  adding: content/MemSum/.git/logs/ (stored 0%)\n",
            "  adding: content/MemSum/.git/logs/refs/ (stored 0%)\n",
            "  adding: content/MemSum/.git/logs/refs/heads/ (stored 0%)\n",
            "  adding: content/MemSum/.git/logs/refs/heads/main (deflated 27%)\n",
            "  adding: content/MemSum/.git/logs/refs/remotes/ (stored 0%)\n",
            "  adding: content/MemSum/.git/logs/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/MemSum/.git/logs/refs/remotes/origin/HEAD (deflated 27%)\n",
            "  adding: content/MemSum/.git/logs/HEAD (deflated 27%)\n",
            "  adding: content/MemSum/.git/info/ (stored 0%)\n",
            "  adding: content/MemSum/.git/info/exclude (deflated 28%)\n",
            "  adding: content/MemSum/.git/hooks/ (stored 0%)\n",
            "  adding: content/MemSum/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "  adding: content/MemSum/.git/hooks/update.sample (deflated 68%)\n",
            "  adding: content/MemSum/.git/hooks/pre-commit.sample (deflated 45%)\n",
            "  adding: content/MemSum/.git/hooks/pre-merge-commit.sample (deflated 39%)\n",
            "  adding: content/MemSum/.git/hooks/fsmonitor-watchman.sample (deflated 52%)\n",
            "  adding: content/MemSum/.git/hooks/post-update.sample (deflated 27%)\n",
            "  adding: content/MemSum/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "  adding: content/MemSum/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "  adding: content/MemSum/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "  adding: content/MemSum/.git/hooks/pre-push.sample (deflated 50%)\n",
            "  adding: content/MemSum/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "  adding: content/MemSum/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "  adding: content/MemSum/.git/packed-refs (deflated 27%)\n",
            "  adding: content/MemSum/.git/config (deflated 33%)\n",
            "  adding: content/MemSum/.git/refs/ (stored 0%)\n",
            "  adding: content/MemSum/.git/refs/tags/ (stored 0%)\n",
            "  adding: content/MemSum/.git/refs/heads/ (stored 0%)\n",
            "  adding: content/MemSum/.git/refs/heads/main (stored 0%)\n",
            "  adding: content/MemSum/.git/refs/remotes/ (stored 0%)\n",
            "  adding: content/MemSum/.git/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/MemSum/.git/refs/remotes/origin/HEAD (stored 0%)\n",
            "  adding: content/MemSum/.git/index (deflated 50%)\n",
            "  adding: content/MemSum/.git/objects/ (stored 0%)\n",
            "  adding: content/MemSum/.git/objects/info/ (stored 0%)\n",
            "  adding: content/MemSum/.git/objects/pack/ (stored 0%)\n",
            "  adding: content/MemSum/.git/objects/pack/pack-367ffe3ef26a22a9af12b66aadca628d95966dd8.idx (deflated 8%)\n",
            "  adding: content/MemSum/.git/objects/pack/pack-367ffe3ef26a22a9af12b66aadca628d95966dd8.pack (deflated 0%)\n",
            "  adding: content/MemSum/.git/description (deflated 14%)\n",
            "  adding: content/MemSum/.git/HEAD (stored 0%)\n",
            "  adding: content/MemSum/summarizers.py (deflated 84%)\n",
            "  adding: content/MemSum/data/ (stored 0%)\n",
            "  adding: content/MemSum/data/custom_data/ (stored 0%)\n",
            "  adding: content/MemSum/data/custom_data/val_CUSTOM_raw.jsonl (deflated 73%)\n",
            "  adding: content/MemSum/data/custom_data/test_CUSTOM_raw.jsonl (deflated 73%)\n",
            "  adding: content/MemSum/data/custom_data/train_CUSTOM_raw.jsonl (deflated 74%)\n",
            "  adding: content/MemSum/data/.DS_Store (deflated 93%)\n",
            "  adding: content/MemSum/oracle_score_compute.ipynb (deflated 68%)\n",
            "  adding: content/MemSum/MemSum/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/human_eval_results/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/human_eval_results/records_memsum_wo_autostop_neusum.jsonl (deflated 76%)\n",
            "  adding: content/MemSum/MemSum/human_eval_results/records_memsum_neusum.jsonl (deflated 76%)\n",
            "  adding: content/MemSum/MemSum/.git/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/branches/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/logs/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/logs/refs/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/logs/refs/heads/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/logs/refs/heads/main (deflated 27%)\n",
            "  adding: content/MemSum/MemSum/.git/logs/refs/remotes/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/logs/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/logs/refs/remotes/origin/HEAD (deflated 27%)\n",
            "  adding: content/MemSum/MemSum/.git/logs/HEAD (deflated 27%)\n",
            "  adding: content/MemSum/MemSum/.git/info/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/info/exclude (deflated 28%)\n",
            "  adding: content/MemSum/MemSum/.git/hooks/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "  adding: content/MemSum/MemSum/.git/hooks/update.sample (deflated 68%)\n",
            "  adding: content/MemSum/MemSum/.git/hooks/pre-commit.sample (deflated 45%)\n",
            "  adding: content/MemSum/MemSum/.git/hooks/pre-merge-commit.sample (deflated 39%)\n",
            "  adding: content/MemSum/MemSum/.git/hooks/fsmonitor-watchman.sample (deflated 52%)\n",
            "  adding: content/MemSum/MemSum/.git/hooks/post-update.sample (deflated 27%)\n",
            "  adding: content/MemSum/MemSum/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "  adding: content/MemSum/MemSum/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "  adding: content/MemSum/MemSum/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "  adding: content/MemSum/MemSum/.git/hooks/pre-push.sample (deflated 50%)\n",
            "  adding: content/MemSum/MemSum/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "  adding: content/MemSum/MemSum/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "  adding: content/MemSum/MemSum/.git/packed-refs (deflated 27%)\n",
            "  adding: content/MemSum/MemSum/.git/config (deflated 33%)\n",
            "  adding: content/MemSum/MemSum/.git/refs/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/refs/tags/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/refs/heads/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/refs/heads/main (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/refs/remotes/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/refs/remotes/origin/HEAD (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/index (deflated 50%)\n",
            "  adding: content/MemSum/MemSum/.git/objects/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/objects/info/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/objects/pack/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/.git/objects/pack/pack-bd2f3e3aa631e34eb4bd6d06e77d2d153b42ecb7.pack (deflated 0%)\n",
            "  adding: content/MemSum/MemSum/.git/objects/pack/pack-bd2f3e3aa631e34eb4bd6d06e77d2d153b42ecb7.idx (deflated 9%)\n",
            "  adding: content/MemSum/MemSum/.git/description (deflated 14%)\n",
            "  adding: content/MemSum/MemSum/.git/HEAD (stored 0%)\n",
            "  adding: content/MemSum/MemSum/summarizers.py (deflated 84%)\n",
            "  adding: content/MemSum/MemSum/data/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/data/val_CUSTOM_raw.jsonl (deflated 99%)\n",
            "  adding: content/MemSum/MemSum/data/custom_data/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/data/custom_data/val_CUSTOM_raw.jsonl (deflated 73%)\n",
            "  adding: content/MemSum/MemSum/data/custom_data/test_CUSTOM_raw.jsonl (deflated 73%)\n",
            "  adding: content/MemSum/MemSum/data/custom_data/train_CUSTOM_raw.jsonl (deflated 74%)\n",
            "  adding: content/MemSum/MemSum/data/train_CUSTOM_labelled.jsonl (deflated 76%)\n",
            "  adding: content/MemSum/MemSum/data/.DS_Store (deflated 93%)\n",
            "  adding: content/MemSum/MemSum/oracle_score_compute.ipynb (deflated 68%)\n",
            "  adding: content/MemSum/MemSum/MemSum/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/human_eval_results/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/human_eval_results/records_memsum_wo_autostop_neusum.jsonl (deflated 76%)\n",
            "  adding: content/MemSum/MemSum/MemSum/human_eval_results/records_memsum_neusum.jsonl (deflated 76%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/branches/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/logs/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/logs/refs/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/logs/refs/heads/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/logs/refs/heads/main (deflated 27%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/logs/refs/remotes/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/logs/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/logs/refs/remotes/origin/HEAD (deflated 27%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/logs/HEAD (deflated 27%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/info/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/info/exclude (deflated 28%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/hooks/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/hooks/update.sample (deflated 68%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/hooks/pre-commit.sample (deflated 45%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/hooks/pre-merge-commit.sample (deflated 39%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/hooks/fsmonitor-watchman.sample (deflated 52%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/hooks/post-update.sample (deflated 27%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/hooks/pre-push.sample (deflated 50%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/packed-refs (deflated 27%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/config (deflated 33%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/refs/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/refs/tags/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/refs/heads/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/refs/heads/main (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/refs/remotes/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/refs/remotes/origin/HEAD (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/index (deflated 50%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/objects/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/objects/info/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/objects/pack/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/objects/pack/pack-367ffe3ef26a22a9af12b66aadca628d95966dd8.idx (deflated 8%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/objects/pack/pack-367ffe3ef26a22a9af12b66aadca628d95966dd8.pack (deflated 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/description (deflated 14%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.git/HEAD (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/summarizers.py (deflated 84%)\n",
            "  adding: content/MemSum/MemSum/MemSum/data/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/data/val_CUSTOM_raw.jsonl (deflated 99%)\n",
            "  adding: content/MemSum/MemSum/MemSum/data/custom_data/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/data/custom_data/val_CUSTOM_raw.jsonl (deflated 73%)\n",
            "  adding: content/MemSum/MemSum/MemSum/data/custom_data/test_CUSTOM_raw.jsonl (deflated 73%)\n",
            "  adding: content/MemSum/MemSum/MemSum/data/custom_data/train_CUSTOM_raw.jsonl (deflated 74%)\n",
            "  adding: content/MemSum/MemSum/MemSum/data/train_CUSTOM_labelled.jsonl (deflated 76%)\n",
            "  adding: content/MemSum/MemSum/MemSum/data/.DS_Store (deflated 93%)\n",
            "  adding: content/MemSum/MemSum/MemSum/oracle_score_compute.ipynb (deflated 68%)\n",
            "  adding: content/MemSum/MemSum/MemSum/log/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/log/MemSum_Full/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/log/MemSum_Full/custom_data/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/log/MemSum_Full/custom_data/200dim/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/log/MemSum_Full/custom_data/200dim/run1/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/log/MemSum_Full/custom_data/200dim/run1/gpu_usage.log (deflated 74%)\n",
            "  adding: content/MemSum/MemSum/MemSum/log/MemSum_Full/custom_data/200dim/run1/train.log (deflated 87%)\n",
            "  adding: content/MemSum/MemSum/MemSum/requirements.txt (deflated 6%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/data_preprocessing/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/data_preprocessing/MemSum/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/data_preprocessing/MemSum/utils.py (deflated 76%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/data_preprocessing/MemSum/(NOT USED)create_dataset_faster.sh (deflated 35%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/data_preprocessing/MemSum/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/data_preprocessing/MemSum/.ipynb_checkpoints/create_dataset_faster-checkpoint.py (deflated 76%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/data_preprocessing/MemSum/.ipynb_checkpoints/utils-checkpoint.py (deflated 76%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/data_preprocessing/MemSum/.ipynb_checkpoints/create_dataset_faster-checkpoint.sh (deflated 35%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/data_preprocessing/MemSum/(NOT USED)merge_files.py (deflated 52%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/data_preprocessing/MemSum/(NOT USED)create_dataset_faster.py (deflated 76%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/data_preprocessing/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/data_preprocessing/.ipynb_checkpoints/Untitled-checkpoint.ipynb (deflated 74%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/MemSum_Full/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/MemSum_Full/model.py (deflated 80%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/MemSum_Full/utils.py (deflated 64%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/MemSum_Full/train.py (deflated 77%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/MemSum_Full/datautils.py (deflated 75%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/MemSum_Full/get_optimal_batch.py (deflated 57%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/MemSum_Full/__pycache__/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/MemSum_Full/__pycache__/utils.cpython-37.pyc (deflated 38%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/MemSum_Full/__pycache__/model.cpython-37.pyc (deflated 61%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/MemSum_Full/__pycache__/utils.cpython-310.pyc (deflated 41%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/MemSum_Full/__pycache__/datautils.cpython-310.pyc (deflated 55%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/MemSum_Full/__pycache__/datautils.cpython-37.pyc (deflated 57%)\n",
            "  adding: content/MemSum/MemSum/MemSum/src/MemSum_Full/__pycache__/model.cpython-310.pyc (deflated 59%)\n",
            "  adding: content/MemSum/MemSum/MemSum/config/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/config/training_config.txt (deflated 51%)\n",
            "  adding: content/MemSum/MemSum/MemSum/images/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/images/human_evaluation_interface.png (deflated 8%)\n",
            "  adding: content/MemSum/MemSum/MemSum/Data_processing_training_and_testing_for_MemSum.ipynb (deflated 73%)\n",
            "  adding: content/MemSum/MemSum/MemSum/MemSum_Human_Evaluation.ipynb (deflated 89%)\n",
            "  adding: content/MemSum/MemSum/MemSum/.DS_Store (deflated 91%)\n",
            "  adding: content/MemSum/MemSum/MemSum/slides_for_paper.pdf (deflated 10%)\n",
            "  adding: content/MemSum/MemSum/MemSum/model/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/model/MemSum_Full/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/model/MemSum_Full/custom_data/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/model/MemSum_Full/custom_data/200dim/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/model/MemSum_Full/custom_data/200dim/run1/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/model/MemSum_Full/custom_data/200dim/run1/model_batch_1000.pt (deflated 8%)\n",
            "  adding: content/MemSum/MemSum/MemSum/model/MemSum_Full/custom_data/200dim/run1/model_batch_3000.pt (deflated 8%)\n",
            "  adding: content/MemSum/MemSum/MemSum/model/MemSum_Full/custom_data/200dim/run1/model_batch_2000.pt (deflated 8%)\n",
            "  adding: content/MemSum/MemSum/MemSum/model/MemSum_Full/custom_data/200dim/run1/model_batch_1382.pt (deflated 8%)\n",
            "  adding: content/MemSum/MemSum/MemSum/model/MemSum_Full/custom_data/200dim/run1/model_batch_691.pt (deflated 8%)\n",
            "  adding: content/MemSum/MemSum/MemSum/model/MemSum_Full/custom_data/200dim/run1/model_batch_2073.pt (deflated 8%)\n",
            "  adding: content/MemSum/MemSum/MemSum/model/MemSum_Full/custom_data/200dim/run1/model_batch_2764.pt (deflated 8%)\n",
            "  adding: content/MemSum/MemSum/MemSum/model/MemSum_Full/custom_data/200dim/run1/model_batch_3455.pt (deflated 8%)\n",
            "  adding: content/MemSum/MemSum/MemSum/model/glove/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/model/glove/vocabulary_200dim.pkl (deflated 47%)\n",
            "  adding: content/MemSum/MemSum/MemSum/model/glove/unigram_embeddings_200dim.pkl (deflated 9%)\n",
            "  adding: content/MemSum/MemSum/MemSum/README.md (deflated 66%)\n",
            "  adding: content/MemSum/MemSum/MemSum/__pycache__/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/MemSum/__pycache__/summarizers.cpython-310.pyc (deflated 51%)\n",
            "  adding: content/MemSum/MemSum/log/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/log/MemSum_Full/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/log/MemSum_Full/custom_data/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/log/MemSum_Full/custom_data/200dim/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/log/MemSum_Full/custom_data/200dim/run1/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/log/MemSum_Full/custom_data/200dim/run1/gpu_usage.log (deflated 74%)\n",
            "  adding: content/MemSum/MemSum/log/MemSum_Full/custom_data/200dim/run1/train.log (deflated 70%)\n",
            "  adding: content/MemSum/MemSum/requirements.txt (deflated 6%)\n",
            "  adding: content/MemSum/MemSum/src/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/src/data_preprocessing/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/src/data_preprocessing/MemSum/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/src/data_preprocessing/MemSum/utils.py (deflated 76%)\n",
            "  adding: content/MemSum/MemSum/src/data_preprocessing/MemSum/(NOT USED)create_dataset_faster.sh (deflated 35%)\n",
            "  adding: content/MemSum/MemSum/src/data_preprocessing/MemSum/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/src/data_preprocessing/MemSum/.ipynb_checkpoints/create_dataset_faster-checkpoint.py (deflated 76%)\n",
            "  adding: content/MemSum/MemSum/src/data_preprocessing/MemSum/.ipynb_checkpoints/utils-checkpoint.py (deflated 76%)\n",
            "  adding: content/MemSum/MemSum/src/data_preprocessing/MemSum/.ipynb_checkpoints/create_dataset_faster-checkpoint.sh (deflated 35%)\n",
            "  adding: content/MemSum/MemSum/src/data_preprocessing/MemSum/(NOT USED)merge_files.py (deflated 52%)\n",
            "  adding: content/MemSum/MemSum/src/data_preprocessing/MemSum/(NOT USED)create_dataset_faster.py (deflated 76%)\n",
            "  adding: content/MemSum/MemSum/src/data_preprocessing/MemSum/__pycache__/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/src/data_preprocessing/MemSum/__pycache__/utils.cpython-310.pyc (deflated 51%)\n",
            "  adding: content/MemSum/MemSum/src/data_preprocessing/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/src/data_preprocessing/.ipynb_checkpoints/Untitled-checkpoint.ipynb (deflated 74%)\n",
            "  adding: content/MemSum/MemSum/src/MemSum_Full/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/src/MemSum_Full/model.py (deflated 80%)\n",
            "  adding: content/MemSum/MemSum/src/MemSum_Full/utils.py (deflated 64%)\n",
            "  adding: content/MemSum/MemSum/src/MemSum_Full/train.py (deflated 77%)\n",
            "  adding: content/MemSum/MemSum/src/MemSum_Full/datautils.py (deflated 75%)\n",
            "  adding: content/MemSum/MemSum/src/MemSum_Full/get_optimal_batch.py (deflated 57%)\n",
            "  adding: content/MemSum/MemSum/src/MemSum_Full/__pycache__/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/src/MemSum_Full/__pycache__/utils.cpython-37.pyc (deflated 38%)\n",
            "  adding: content/MemSum/MemSum/src/MemSum_Full/__pycache__/model.cpython-37.pyc (deflated 61%)\n",
            "  adding: content/MemSum/MemSum/src/MemSum_Full/__pycache__/utils.cpython-310.pyc (deflated 40%)\n",
            "  adding: content/MemSum/MemSum/src/MemSum_Full/__pycache__/datautils.cpython-310.pyc (deflated 55%)\n",
            "  adding: content/MemSum/MemSum/src/MemSum_Full/__pycache__/datautils.cpython-37.pyc (deflated 57%)\n",
            "  adding: content/MemSum/MemSum/src/MemSum_Full/__pycache__/model.cpython-310.pyc (deflated 59%)\n",
            "  adding: content/MemSum/MemSum/config/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/config/training_config.txt (deflated 51%)\n",
            "  adding: content/MemSum/MemSum/images/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/images/human_evaluation_interface.png (deflated 8%)\n",
            "  adding: content/MemSum/MemSum/Data_processing_training_and_testing_for_MemSum.ipynb (deflated 73%)\n",
            "  adding: content/MemSum/MemSum/MemSum_Human_Evaluation.ipynb (deflated 89%)\n",
            "  adding: content/MemSum/MemSum/.DS_Store (deflated 91%)\n",
            "  adding: content/MemSum/MemSum/slides_for_paper.pdf (deflated 10%)\n",
            "  adding: content/MemSum/MemSum/model/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/model/MemSum_Full/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/model/MemSum_Full/custom_data/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/model/MemSum_Full/custom_data/200dim/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/model/MemSum_Full/custom_data/200dim/run1/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/model/glove/ (stored 0%)\n",
            "  adding: content/MemSum/MemSum/model/glove/vocabulary_200dim.pkl (deflated 47%)\n",
            "  adding: content/MemSum/MemSum/model/glove/unigram_embeddings_200dim.pkl (deflated 9%)\n",
            "  adding: content/MemSum/MemSum/README.md (deflated 66%)\n",
            "  adding: content/MemSum/requirements.txt (deflated 6%)\n",
            "  adding: content/MemSum/src/ (stored 0%)\n",
            "  adding: content/MemSum/src/data_preprocessing/ (stored 0%)\n",
            "  adding: content/MemSum/src/data_preprocessing/MemSum/ (stored 0%)\n",
            "  adding: content/MemSum/src/data_preprocessing/MemSum/utils.py (deflated 76%)\n",
            "  adding: content/MemSum/src/data_preprocessing/MemSum/(NOT USED)create_dataset_faster.sh (deflated 35%)\n",
            "  adding: content/MemSum/src/data_preprocessing/MemSum/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/MemSum/src/data_preprocessing/MemSum/.ipynb_checkpoints/create_dataset_faster-checkpoint.py (deflated 76%)\n",
            "  adding: content/MemSum/src/data_preprocessing/MemSum/.ipynb_checkpoints/utils-checkpoint.py (deflated 76%)\n",
            "  adding: content/MemSum/src/data_preprocessing/MemSum/.ipynb_checkpoints/create_dataset_faster-checkpoint.sh (deflated 35%)\n",
            "  adding: content/MemSum/src/data_preprocessing/MemSum/(NOT USED)merge_files.py (deflated 52%)\n",
            "  adding: content/MemSum/src/data_preprocessing/MemSum/(NOT USED)create_dataset_faster.py (deflated 76%)\n",
            "  adding: content/MemSum/src/data_preprocessing/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/MemSum/src/data_preprocessing/.ipynb_checkpoints/Untitled-checkpoint.ipynb (deflated 74%)\n",
            "  adding: content/MemSum/src/MemSum_Full/ (stored 0%)\n",
            "  adding: content/MemSum/src/MemSum_Full/model.py (deflated 80%)\n",
            "  adding: content/MemSum/src/MemSum_Full/utils.py (deflated 64%)\n",
            "  adding: content/MemSum/src/MemSum_Full/train.py (deflated 77%)\n",
            "  adding: content/MemSum/src/MemSum_Full/datautils.py (deflated 75%)\n",
            "  adding: content/MemSum/src/MemSum_Full/get_optimal_batch.py (deflated 57%)\n",
            "  adding: content/MemSum/src/MemSum_Full/__pycache__/ (stored 0%)\n",
            "  adding: content/MemSum/src/MemSum_Full/__pycache__/utils.cpython-37.pyc (deflated 38%)\n",
            "  adding: content/MemSum/src/MemSum_Full/__pycache__/model.cpython-37.pyc (deflated 61%)\n",
            "  adding: content/MemSum/src/MemSum_Full/__pycache__/datautils.cpython-37.pyc (deflated 57%)\n",
            "  adding: content/MemSum/config/ (stored 0%)\n",
            "  adding: content/MemSum/config/training_config.txt (deflated 51%)\n",
            "  adding: content/MemSum/images/ (stored 0%)\n",
            "  adding: content/MemSum/images/human_evaluation_interface.png (deflated 8%)\n",
            "  adding: content/MemSum/Data_processing_training_and_testing_for_MemSum.ipynb (deflated 73%)\n",
            "  adding: content/MemSum/MemSum_Human_Evaluation.ipynb (deflated 89%)\n",
            "  adding: content/MemSum/.DS_Store (deflated 91%)\n",
            "  adding: content/MemSum/slides_for_paper.pdf (deflated 10%)\n",
            "  adding: content/MemSum/README.md (deflated 66%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r ../memsum.zip /content/MemSum/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}